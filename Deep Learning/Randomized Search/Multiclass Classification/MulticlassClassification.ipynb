{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultiClass.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxkKI4x21qkk"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFF1r67Oqs93"
      },
      "source": [
        "trainDataset = pd.read_csv(\"/content/fashion_mnist_train.csv\")\n",
        "testDataset = pd.read_csv(\"/content/fashion_mnist_test.csv\")\n",
        "\n",
        "XTrain = trainDataset.iloc[:, 1:785]\n",
        "YTrain = trainDataset.iloc[:, 0:1]\n",
        "\n",
        "XTest = testDataset.iloc[:, 1:785]\n",
        "YTest = testDataset.iloc[:, 0:1]\n",
        "\n",
        "YCategorizedTrain = keras.utils.to_categorical(YTrain);\n",
        "YCategorizedTest = keras.utils.to_categorical(YTest);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FINakmX80C4y"
      },
      "source": [
        "def createModel (layers=5, neurons=16, alpha=1.0e-05, activation='relu'):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(784,)))\n",
        "    for i in range(layers):\n",
        "        model.add(Dense(neurons, activation=activation))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    optimizer = Adam(learning_rate=alpha)\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = KerasClassifier(build_fn=createModel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2M1nLDh2NZZt",
        "outputId": "d1ed21ac-f79a-48a2-eb2c-1b81cfba2d19"
      },
      "source": [
        "layers = list(range(5,31))\n",
        "activation = ['relu', 'tanh', 'softmax', 'softplus', 'sigmoid']\n",
        "neurons = list(range(16,1024))\n",
        "alpha = [0.01, 0.001, 0.0001, 0.00001]\n",
        "parameters = dict(layers=layers, activation=activation, neurons=neurons, alpha=alpha)\n",
        "\n",
        "randomized = RandomizedSearchCV(estimator=model, param_distributions=parameters, cv=3, verbose=2, n_iter=10)\n",
        "randomized.fit(XTrain, YCategorizedTrain)\n",
        "print(\"Best Parameters: \", randomized.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "[CV] neurons=662, layers=7, alpha=1e-05, activation=tanh .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1250/1250 [==============================] - 42s 33ms/step - loss: 0.9877 - accuracy: 0.6811\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.4980 - accuracy: 0.8227\n",
            "[CV]  neurons=662, layers=7, alpha=1e-05, activation=tanh, total=  49.2s\n",
            "[CV] neurons=662, layers=7, alpha=1e-05, activation=tanh .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   49.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1250/1250 [==============================] - 43s 34ms/step - loss: 0.9586 - accuracy: 0.6916\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.4962 - accuracy: 0.8171\n",
            "[CV]  neurons=662, layers=7, alpha=1e-05, activation=tanh, total=  49.7s\n",
            "[CV] neurons=662, layers=7, alpha=1e-05, activation=tanh .............\n",
            "1250/1250 [==============================] - 42s 33ms/step - loss: 0.9894 - accuracy: 0.6786\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.5033 - accuracy: 0.8178\n",
            "[CV]  neurons=662, layers=7, alpha=1e-05, activation=tanh, total=  48.3s\n",
            "[CV] neurons=261, layers=24, alpha=1e-05, activation=relu ............\n",
            "1250/1250 [==============================] - 31s 24ms/step - loss: 1.3802 - accuracy: 0.4995\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.6011 - accuracy: 0.7869\n",
            "[CV]  neurons=261, layers=24, alpha=1e-05, activation=relu, total=  35.0s\n",
            "[CV] neurons=261, layers=24, alpha=1e-05, activation=relu ............\n",
            "1250/1250 [==============================] - 31s 24ms/step - loss: 1.3728 - accuracy: 0.5184\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.6343 - accuracy: 0.7669\n",
            "[CV]  neurons=261, layers=24, alpha=1e-05, activation=relu, total=  34.5s\n",
            "[CV] neurons=261, layers=24, alpha=1e-05, activation=relu ............\n",
            "1250/1250 [==============================] - 31s 24ms/step - loss: 1.3919 - accuracy: 0.5277\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.5817 - accuracy: 0.7985\n",
            "[CV]  neurons=261, layers=24, alpha=1e-05, activation=relu, total=  34.6s\n",
            "[CV] neurons=439, layers=6, alpha=0.001, activation=tanh .............\n",
            "1250/1250 [==============================] - 20s 15ms/step - loss: 1.1708 - accuracy: 0.5552\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.2569 - accuracy: 0.4951\n",
            "[CV]  neurons=439, layers=6, alpha=0.001, activation=tanh, total=  23.4s\n",
            "[CV] neurons=439, layers=6, alpha=0.001, activation=tanh .............\n",
            "1250/1250 [==============================] - 20s 15ms/step - loss: 1.1087 - accuracy: 0.5763\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.9851 - accuracy: 0.6194\n",
            "[CV]  neurons=439, layers=6, alpha=0.001, activation=tanh, total=  23.6s\n",
            "[CV] neurons=439, layers=6, alpha=0.001, activation=tanh .............\n",
            "1250/1250 [==============================] - 19s 15ms/step - loss: 1.1275 - accuracy: 0.5653\n",
            "625/625 [==============================] - 4s 5ms/step - loss: 1.1336 - accuracy: 0.5215\n",
            "[CV]  neurons=439, layers=6, alpha=0.001, activation=tanh, total=  23.7s\n",
            "[CV] neurons=529, layers=24, alpha=0.01, activation=relu .............\n",
            "1250/1250 [==============================] - 94s 75ms/step - loss: 538685.4976 - accuracy: 0.1036\n",
            "625/625 [==============================] - 12s 18ms/step - loss: 2.3036 - accuracy: 0.1003\n",
            "[CV]  neurons=529, layers=24, alpha=0.01, activation=relu, total= 1.8min\n",
            "[CV] neurons=529, layers=24, alpha=0.01, activation=relu .............\n",
            "1250/1250 [==============================] - 95s 75ms/step - loss: 1708100.7339 - accuracy: 0.1010\n",
            "625/625 [==============================] - 12s 19ms/step - loss: 2.3039 - accuracy: 0.0992\n",
            "[CV]  neurons=529, layers=24, alpha=0.01, activation=relu, total= 1.8min\n",
            "[CV] neurons=529, layers=24, alpha=0.01, activation=relu .............\n",
            "1250/1250 [==============================] - 95s 75ms/step - loss: 210806.1475 - accuracy: 0.1018\n",
            "625/625 [==============================] - 12s 19ms/step - loss: 2.3041 - accuracy: 0.0990\n",
            "[CV]  neurons=529, layers=24, alpha=0.01, activation=relu, total= 1.8min\n",
            "[CV] neurons=293, layers=20, alpha=0.01, activation=tanh .............\n",
            "1250/1250 [==============================] - 33s 25ms/step - loss: 2.7098 - accuracy: 0.0971\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 2.3939 - accuracy: 0.1023\n",
            "[CV]  neurons=293, layers=20, alpha=0.01, activation=tanh, total=  36.9s\n",
            "[CV] neurons=293, layers=20, alpha=0.01, activation=tanh .............\n",
            "1250/1250 [==============================] - 33s 25ms/step - loss: 2.7264 - accuracy: 0.0988\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 2.5224 - accuracy: 0.0992\n",
            "[CV]  neurons=293, layers=20, alpha=0.01, activation=tanh, total=  36.8s\n",
            "[CV] neurons=293, layers=20, alpha=0.01, activation=tanh .............\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 2.6969 - accuracy: 0.1028\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 2.5704 - accuracy: 0.0990\n",
            "[CV]  neurons=293, layers=20, alpha=0.01, activation=tanh, total=  36.3s\n",
            "[CV] neurons=197, layers=16, alpha=1e-05, activation=relu ............\n",
            "1250/1250 [==============================] - 14s 10ms/step - loss: 1.3970 - accuracy: 0.5375\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.5867 - accuracy: 0.7966\n",
            "[CV]  neurons=197, layers=16, alpha=1e-05, activation=relu, total=  16.2s\n",
            "[CV] neurons=197, layers=16, alpha=1e-05, activation=relu ............\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 1.3917 - accuracy: 0.5346\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.5945 - accuracy: 0.7889\n",
            "[CV]  neurons=197, layers=16, alpha=1e-05, activation=relu, total=  16.3s\n",
            "[CV] neurons=197, layers=16, alpha=1e-05, activation=relu ............\n",
            "1250/1250 [==============================] - 14s 10ms/step - loss: 1.3841 - accuracy: 0.5065\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.6018 - accuracy: 0.7887\n",
            "[CV]  neurons=197, layers=16, alpha=1e-05, activation=relu, total=  16.4s\n",
            "[CV] neurons=109, layers=13, alpha=0.001, activation=relu ............\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.8768 - accuracy: 0.6865\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.6062 - accuracy: 0.8048\n",
            "[CV]  neurons=109, layers=13, alpha=0.001, activation=relu, total=   8.3s\n",
            "[CV] neurons=109, layers=13, alpha=0.001, activation=relu ............\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.8913 - accuracy: 0.6831\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.5279 - accuracy: 0.8165\n",
            "[CV]  neurons=109, layers=13, alpha=0.001, activation=relu, total=   8.3s\n",
            "[CV] neurons=109, layers=13, alpha=0.001, activation=relu ............\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.9246 - accuracy: 0.6640\n",
            "625/625 [==============================] - 1s 1ms/step - loss: 0.5533 - accuracy: 0.7994\n",
            "[CV]  neurons=109, layers=13, alpha=0.001, activation=relu, total=   8.3s\n",
            "[CV] neurons=316, layers=21, alpha=0.001, activation=relu ............\n",
            "1250/1250 [==============================] - 35s 28ms/step - loss: 1.4538 - accuracy: 0.3933\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.5203 - accuracy: 0.4956\n",
            "[CV]  neurons=316, layers=21, alpha=0.001, activation=relu, total=  40.0s\n",
            "[CV] neurons=316, layers=21, alpha=0.001, activation=relu ............\n",
            "1250/1250 [==============================] - 36s 28ms/step - loss: 1.3453 - accuracy: 0.4247\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.9355 - accuracy: 0.6431\n",
            "[CV]  neurons=316, layers=21, alpha=0.001, activation=relu, total=  40.9s\n",
            "[CV] neurons=316, layers=21, alpha=0.001, activation=relu ............\n",
            "1250/1250 [==============================] - 36s 28ms/step - loss: 1.2826 - accuracy: 0.4519\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.4632 - accuracy: 0.4239\n",
            "[CV]  neurons=316, layers=21, alpha=0.001, activation=relu, total=  40.6s\n",
            "[CV] neurons=439, layers=5, alpha=0.01, activation=relu ..............\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 73.8839 - accuracy: 0.1732\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 2.3050 - accuracy: 0.0976\n",
            "[CV]  neurons=439, layers=5, alpha=0.01, activation=relu, total=  21.2s\n",
            "[CV] neurons=439, layers=5, alpha=0.01, activation=relu ..............\n",
            "1250/1250 [==============================] - 17s 14ms/step - loss: 58.5502 - accuracy: 0.5868\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.8449 - accuracy: 0.6532\n",
            "[CV]  neurons=439, layers=5, alpha=0.01, activation=relu, total=  21.0s\n",
            "[CV] neurons=439, layers=5, alpha=0.01, activation=relu ..............\n",
            "1250/1250 [==============================] - 17s 14ms/step - loss: 30.6047 - accuracy: 0.5468\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 1.0368 - accuracy: 0.5900\n",
            "[CV]  neurons=439, layers=5, alpha=0.01, activation=relu, total=  21.0s\n",
            "[CV] neurons=572, layers=6, alpha=0.001, activation=relu .............\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 3.2057 - accuracy: 0.7155\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.4922 - accuracy: 0.8288\n",
            "[CV]  neurons=572, layers=6, alpha=0.001, activation=relu, total=  33.5s\n",
            "[CV] neurons=572, layers=6, alpha=0.001, activation=relu .............\n",
            "1250/1250 [==============================] - 29s 22ms/step - loss: 2.8987 - accuracy: 0.7233\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.4622 - accuracy: 0.8319\n",
            "[CV]  neurons=572, layers=6, alpha=0.001, activation=relu, total=  33.8s\n",
            "[CV] neurons=572, layers=6, alpha=0.001, activation=relu .............\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 2.9166 - accuracy: 0.7219\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.5248 - accuracy: 0.8110\n",
            "[CV]  neurons=572, layers=6, alpha=0.001, activation=relu, total=  33.2s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 18.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 42s 22ms/step - loss: 2.2467 - accuracy: 0.7407\n",
            "Best Parameters:  {'neurons': 572, 'layers': 6, 'alpha': 0.001, 'activation': 'relu'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRPYdA-enegq",
        "outputId": "ce23d618-029e-4a1e-f441-84f14f0531a1"
      },
      "source": [
        "bestModel = randomized.best_estimator_\n",
        "YPred = bestModel.predict(XTest)\n",
        "\n",
        "accuracy = 0\n",
        "YPred = list(YPred)\n",
        "YTest = list(YTest['label'])\n",
        "for i in range(len(YPred)):\n",
        "    if YPred[i] == YTest[i]:\n",
        "        accuracy = accuracy + 1\n",
        "accuracy = (accuracy/len(YPred))*100\n",
        "print(\"Accuracy: \", accuracy) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  84.11\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}